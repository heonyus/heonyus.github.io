---
layout: post
title: "The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain(1958)"
date: 2022-06-04
category: ML
tags: [paper, perceptron]
---

# Introduction

### McCulloch-Pitts Neuron

이 문서가 다루는 연구의 근본적인 출발점은 **학습 능력이 없는 초기 인공 뉴런 모델의 한계**를 극복하는 것입니다.<br>
워런 맥컬록과 월터 피츠가 제안한 초기 논리 뉴런은 AND, OR 같은 특정 논리 기능을 수행하도록 가중치와 임계값이 미리 고정되어 있었습니다.<br>

- 맥컬록-피츠 뉴런(McCulloch-Pitts Neuron, 줄여서 MCP 뉴런, 1943)의 작동 방식

<p align="center">
    <img alt="표1" src="https://media.geeksforgeeks.org/wp-content/uploads/20210127110754/model1.jpg" referrerpolicy="no-referrer" loading="lazy" />
</p>


1.  **이진 입력과 출력**: 뉴런은 여러 개의 입력을 받으며, 각 입력과 출력은 '켜짐'(1) 또는 '꺼짐'(0)의 두 가지 상태만 가집니다.<br>
2.  **가중치와 임계값**: 각 입력 신호는 고유한 가중치(weight)를 가집니다.<br>
뉴런은 모든 입력 신호와 해당 가중치를 곱한 값들을 모두 합산합니다.<br>
이 합산된 값이 미리 정해진 **임계값(threshold)**보다 크거나 같으면 뉴런은 '켜짐'(1) 상태가 되고, 그렇지 않으면 '꺼짐'(0) 상태를 유지합니다.<br>

모든 입력($x_i$)과 각각의 가중치($w_i$)를 곱하여 합산합니다. 이를 **순 입력 함수(Net Input Function)** 라고 합니다.

$$u = \sum_{i=1}^{n} w_i x_i$$


* $u$ 는 입력 값들의 가중치 합
* $x_i$ 는 $i$번째 입력 신호 (0 또는 1)
* $w_i$ 는 $i$번째 입력의 가중치
* $n$ 은 전체 입력의 개수

그 다음, 이 합산된 값($u$)을 임계값($\theta$)과 비교하는 **활성화 함수(Activation Function)** 를 통해 최종 출력($y$)을 결정합니다.

$$y = \begin{cases} 1 & \text{if } u \ge \theta \\ 0 & \text{if } u < \theta \end{cases}$$


> **여러 입력 신호의 총합이 특정 기준치(임계값)를 넘어서면 뉴런이 활성화되어 1을 출력하고, 그렇지 않으면 비활성화 상태인 0을 출력**

### Backgroung

이러한 배경에서 프랭크 로젠블랫(Frank Rosenblatt)은 **'학습'이라는 개념을 도입**하여 이 문제를 해결하고자 했습니다.<br>

<p align="center">
  <img alt="표1" src="https://i.imgur.com/ALYPQKe.png" referrerpolicy="no-referrer" loading="lazy" />
</p>


- **연구의 핵심 목표**: 뇌가 정보를 저장하고 구성하는 방식을 모방하여 주어진 데이터를 통해 **스스로 가중치(weights)와 편향(threshold)을 조정하여 올바른 결정을 내리도록 훈련시킬 수 있는 신경망 모델, 즉 '퍼셉트론'을 제안하고 그 학습 원리를 증명**하는 것

## Data & Variable

퍼셉트론을 학습시키기 위해 사용되는 데이터는 '훈련 집합(Training Set)'입니다.<br>

* **데이터의 형태**: 훈련 집합은 여러 개의 '훈련 샘플(training example)'로 구성<br>
각 샘플은 입력 패턴 벡터($x_k$)와 이 입력에 대해 나와야 하는 **정답(원하는 출력 값, $\hat{y}_k$)**의 순서쌍 $(x_k, \hat{y}_k)$으로 이루어져 있습니다.
    * **입력($x_k$)**: 흑백 이미지를 표현하는 픽셀 값들의 벡터처럼, 패턴을 나타내는 숫자 벡터입니다.<br>
    (0,0), (0,1)과 같은 이진 입력 벡터를 사용
    * **정답($\hat{y}_k$)**: 각 입력 패턴이 어떤 클래스에 속하는지를 나타내는 값으로, 주로 0 또는 1의 이진 값을 가집니다.<br>
    예를 들어, 입력 이미지가 'L'자 모양이면 1, 아니면 0으로 설정할 수 있습니다.<br>

* **핵심 변수 (학습 파라미터)**: 퍼셉트론 모델에서 학습을 통해 최적화되는 핵심 변수<br>
    * **가중치($w_i$)**: 각 입력 특성($x_i$)이 출력에 얼마나 중요한 영향을 미치는지를 나타내는 실수 값입니다.<br>
    * **편향($\vartheta$, threshold)**: 뉴런이 얼마나 쉽게 활성화될지를 결정하는 임계값 역할을 하는 실수 값입니다.<br>

<p align="center">
  <img alt="표1" src="https://i.imgur.com/fEHATpP.png
" referrerpolicy="no-referrer" loading="lazy" />
</p>

이 학습 과정의 최종 목표는 모든 훈련 데이터에 대해 올바른 출력을 내놓는 최적의 가중치 벡터($w^*$)와 편향($\vartheta^*$)을 찾는 것입니다.

### **Core Idea**

"실수를 통해 배운다"는 개념을 알고리즘으로 구현한 **퍼셉트론 학습 알고리즘(Perceptron Learning Algorithm)**<br>
<br>
"만약 퍼셉트론이 어떤 입력에 대해 잘못된 예측을 한다면, 그 실수를 바로잡는 방향으로 가중치와 편향을 조금씩 수정한다. 이 과정을 모든 데이터에 대해 반복하면 결국 모든 데이터를 올바르게 분류할 수 있게 될 것이다."<br>
<br>

- 이 아이디어를 구현하는 핵심적인 메커니즘은 다음과 같은 **가중치 업데이트 규칙**입니다.

$$w_{new} = w_{old} + \lambda(\hat{y}_k - y_k)x_k$$ 
$$\vartheta_{new} = \vartheta_{old} + \lambda(\hat{y}_k - y_k)$$

* $(\hat{y}_k - y_k)$는 오차(error)를 의미
    * **예측이 맞았을 경우**: $y_k = \hat{y}_k$ 이므로 오차는 0이 되고, 가중치는 업데이트되지 않음<br>
    즉, "잘하고 있으니 그대로 유지한다"는 의미입니다.<br>
    * **예측이 틀렸을 경우**: 오차는 0이 아니며, 이 오차 값에 비례하여 가중치가 조정<br>
    예를 들어, 출력이 0이 나와야 하는데 1이 나왔다면($\hat{y}_k=0, y_k=1$), 오차는 -1이 되어 입력 벡터 $x_k$의 반대 방향으로 가중치를 조정하여 다음에는 해당 입력에 덜 활성화되도록 만듭니다.<br>

    1.  **오차 계산**:
    $$\hat{y}_k - y_k = 0 - 1 = -1$$

    2.  **가중치 업데이트 수식에 대입**:
    $$w_{new} = w_{old} + \lambda(-1)x_k$$

    3.  **최종 수식**:
    $$w_{new} = w_{old} - \lambda x_k$$


이 간단하면서도 강력한 규칙을 통해, 퍼셉트론은 복잡한 패턴을 가진 데이터 집합 속에서 스스로 결정 경계(decision boundary)를 찾아내는 능력을 갖추게 됩니다.

# Experiment

## Objective
<p align="center">
  <img alt="표1" src="https://i.imgur.com/ML8mGrc.png" referrerpolicy="no-referrer" loading="lazy" />
</p>


이 실험의 목표는 4개의 데이터 샘플을 이용해, 퍼셉트론이 논리 연산 'OR'을 수행하도록 학습시키는 것입니다.

* **학습 데이터**:

    | 입력 ($x_1, x_2$) | 정답 ($\hat{y}$) |
    | :--------------: | :--------------: |
    |      (0, 0)      |        0         |
    |      (0, 1)      |        1         |
    |      (1, 0)      |        1         |
    |      (1, 1)      |        1         |

* **초기 설정**:
    * 학습률 $\lambda = 1$.
    * 편향($\vartheta$)을 가중치 벡터에 포함시키기 위해, 입력 맨 앞에 상수 1을 추가합니다. (입력 벡터: $x = (1, x_1, x_2)$)
    * 가중치 벡터 $w = (\vartheta, w_1, w_2)$를 모두 0으로 초기화합니다. $w = (0, 0, 0)$.


### **Step 0: 초기화**

<p align="center">
  <img alt="표1" src="https://i.imgur.com/KbP86jG.png" referrerpolicy="no-referrer" loading="lazy" />
</p>


* **What**: 학습을 시작하기 전, 가중치 벡터 $w$를 `(0, 0, 0)`으로 설정했습니다.
* **How**: $w_{initial} = (0, 0, 0)$
* **Why**: 어떤 사전 정보도 없는 '백지상태'에서 학습을 시작하기 위함입니다.
* **Result**: 모델은 아직 아무것도 학습하지 않은 상태입니다.

### **Step 1 ~ 4: 첫 번째 Epoch (데이터 1바퀴 학습)**

<p align="center">
  <img alt="표1" src="https://i.imgur.com/tJwoR9z.png" referrerpolicy="no-referrer" loading="lazy" />
</p>


#### **`샘플 1: x = (1, 0, 0), 정답 = 0`**

* **What**: 첫 번째 데이터 `(0, 0)`를 모델에 입력하고 결과를 예측했습니다.
* **How**:
    * 가중합 계산: $\xi = w \cdot x = (0, 0, 0) \cdot (1, 0, 0) = 0$
    * 출력 계산: 문서의 추적 과정에 따르면 $y = 0$ 으로 예측되었습니다.<br>
* **Why**: 현재 가중치가 이 데이터를 올바르게 분류하는지 확인하기 위함입니다.<br>
* **Result**: 예측($y=0$)이 정답($\hat{y}=0$)과 일치했습니다.<br>
따라서 **가중치 업데이트는 일어나지 않습니다.** $w$는 `(0, 0, 0)`을 유지합니다.<br>

#### **`샘플 2: x = (1, 0, 1), 정답 = 1` (첫 번째 실수 발생!)**

* **What**: 두 번째 데이터 `(0, 1)`에 대해 예측하고, 발생한 오류를 수정하기 위해 가중치를 업데이트했습니다.
* **How**:
    * 가중합 계산: $\xi = w \cdot x = (0, 0, 0) \cdot (1, 0, 1) = 0$
    * 출력 계산: $y=0$으로 예측.<br>
    하지만 정답은 $\hat{y}=1$이므로 예측이 틀렸습니다<br>
    * 가중치 업데이트:
        $$w_{new} = w_{old} + \lambda(\hat{y} - y)x$$
        $$w_{new} = (0, 0, 0) + 1(1 - 0)(1, 0, 1) = (1, 0, 1)$$
* **Why**: 모델이 "출력이 1이 나와야 하는데 0이 나왔다"는 실수를 했기 때문에, 가중치를 입력 벡터 방향으로 더해주어 다음에는 이 입력에 대해 더 큰 값이 나오도록 조정하기 위함입니다.<br>
* **Result**: **가중치가 `(1, 0, 1)`로 업데이트되었습니다**.<br>
모델이 첫 학습을 통해 변화했습니다.

#### **`샘플 3 & 4: (1, 1, 0), (1, 1, 1)`**

* **What**: 업데이트된 가중치 `(1, 0, 1)`을 가지고 나머지 두 데이터 `(1, 0)`과 `(1, 1)`을 예측했습니다.
* **How**:
    * `x=(1,1,0)`: $\xi = (1,0,1)\cdot(1,1,0)=1 \rightarrow y=1$. 정답과 일치.
    * `x=(1,1,1)`: $\xi = (1,0,1)\cdot(1,1,1)=2 \rightarrow y=1$. 정답과 일치.
* **Why**: 업데이트된 가중치가 다른 데이터에도 잘 작동하는지 확인하기 위함입니다.
* **Result**: 두 샘플 모두 올바르게 예측되어 **가중치 업데이트는 없습니다**.<br>
첫 번째 Epoch가 끝난 시점의 가중치는 `(1, 0, 1)`입니다.

### **Step 5 ~ : 두 번째 Epoch 이후 (반복 학습)**

<p align="center">
  <img alt="표1" src="https://i.imgur.com/vqgXTjY.png" referrerpolicy="no-referrer" loading="lazy" />
</p>


#### **`샘플 1 재학습: x = (1, 0, 0), 정답 = 0` (새로운 실수 발생!)**

* **What*ㄴㄴ*: 첫 번째 Epoch가 끝났지만 아직 학습이 완료되지 않았으므로, 다시 첫 번째 데이터 `(0, 0)`를 학습했습니다.
* **How**:
    * 가중합 계산: $\xi = w \cdot x = (1, 0, 1) \cdot (1, 0, 0) = 1$
    * 출력 계산: $y=1$로 예측.<br>
    하지만 정답은 $\hat{y}=0$이므로 예측이 틀렸습니다.<br>
    * 가중치 업데이트:
        $$w_{new} = (1, 0, 1) + 1(0 - 1)(1, 0, 0) = (0, 0, 1)$$
* **Why**: Step 2에서 샘플 2를 맞추기 위해 가중치를 조정한 결과, 이번에는 원래 맞추던 샘플 1을 틀리게 된 상황입니다.<br>
이 새로운 실수를 교정하기 위해 다시 가중치를 업데이트합니다.
* **Result**: **가중치가 `(0, 0, 1)`로 업데이트되었습니다**.<br>
이처럼 퍼셉트론 학습은 여러 데이터 샘플 사이에서 최적의 '타협점'을 찾아가는 과정입니다.

### **최종 결과**

이와 같은 과정을 **13단계까지 반복**합니다.<br>
가중치는 실수가 발생할 때마다 계속 업데이트되고, 마침내 모든 4개의 데이터 샘플을 오류 없이 통과하는 순간이 옵니다.

* **What**: 모든 훈련 데이터에 대해 완벽하게 정답을 예측하는 가중치 벡터를 찾았습니다.
* **How**: 여러 번의 반복 학습 끝에 가중치 $w$는 최종적으로 `(0, 1, 1)`에 도달했고, 이 상태에서 모든 데이터 샘플을 올바르게 분류했습니다.<br>
* **Why**: 더 이상 어떤 데이터에서도 실수가 발생하지 않으므로, 가중치 업데이트가 멈추고 학습이 종료(converge)됩니다.
* **Result**: 퍼셉트론은 `(0, 1, 1)`이라는 가중치 값을 통해 **OR 논리 연산을 학습하는 데 성공했습니다.**

---
[실험 코드](https://github.com/heonyus/ai-implementation/blob/main/The-Perceptron/perceptron.ipynb)