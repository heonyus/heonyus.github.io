---
layout: post
title: "A Vector Space Model for Automatic Indexing(1975)"
date: 2022-06-15
tags: [paper, embedding]
---

# Introduction

## What is the problem?

- 핵심 문제: **"어떻게 하면 가장 효과적인 자동 인덱싱(automatic indexing) 시스템을 만들 수 있는가?"** 
    - 여기서 'indexing'이란 문서의 핵심 내용을 나타내는 keywords를 추출하고 가중치를 부여하는 과정을 의미합니다.

- 논문은 이 문제를 '문서 공간(document space)'이라는 기하학적 관점에서 접근합니다.

> 최고의 검색 성능은 문서 공간의 밀도(space density)가 낮을 때<br>
> 즉 각 문서 벡터들이 서로 멀리 떨어져 최대한 분산되어 있을 때 나타난다.

다시 말해, **검색 성능과 문서 공간의 밀도는 반비례 관계**에 있다는 것을 입증하고자 합니다.

## What kind of data?

* **항공역학(Aerodynamics) 분야 문서 424건**
* **의학(Medicine) 분야 문서 450건 (Medlars 컬렉션)**
* **시사(World Affairs) 분야 문서 425건 (TIME 매거진)**

데이터를 변수화하고 처리하는 방식은 논문의 핵심인 벡터 공간 모델(Vector Space Model)을 따릅니다.

<p align="center">
  <img alt="표1" src="https://i.imgur.com/bwE0GiF.png" referrerpolicy="no-referrer" loading="lazy" />
</p>

* **문서의 벡터화**: 각 문서($D_{i}$)는 하나의 고차원 벡터로 표현됩니다.

$$
D_{i} = (d_{i1}, d_{i2}, ..., d_{it})
$$

<p align="center">
  <img alt="표1" src="https://i.imgur.com/xfMQVzi.png" referrerpolicy="no-referrer" loading="lazy" />
</p>

* **차원의 의미**: 벡터의 각 차원은 컬렉션에 존재하는 개별 인덱스 용어($T_{j}$)에 해당합니다.
* **변수(가중치)**: 벡터의 각 요소($d_{ij}$)는 $i$번째 문서에서 $j$번째 용어가 얼마나 중요한지를 나타내는 **가중치(weight)**입니다.
    * **단순 빈도 (Term Frequency, TF)**: 문서 내에서 용어가 등장하는 빈도.
    * **TF-IDF (Term Frequency-Inverse Document Frequency)**: 용어 빈도에 그 용어가 전체 문서에서 얼마나 희소한지를 나타내는 역문서 빈도를 곱한 값.<br>
        * 특정 문서에 자주 나타나지만 전체적으로는 희귀한 용어에 높은 가중치를 부여합니다.

## What is hypothesis?

이 논문의 가장 핵심적인 아이디어와 가설은 **'용어 판별 가치(Term Discrimination Value)'** 개념에 기반합니다.

* **핵심 아이디어**: "good" index term와 "bad" index term은 그 용어가 전체 문서 공간의 구조에 어떤 영향을 미치는지로 판단할 수 있습니다.
* **핵심 가설**: **""good" index term이란, 그 용어가 문서들에 적용되었을 때 전체 문서 공간을 더 넓게 퍼뜨리는(분산시키는; high dicrimination value) 용어이다"**.

<br>
이 가설은 다음과 같은 논리적 귀결을 낳습니다.<br>
<br>

1.  **이상적인 공간**: 사용자의 특정 검색 의도에 대해 관련 있는 문서들끼리만 모여있는 '클러스터'를 형성하고, 관련 없는 문서들과는 멀리 떨어져 있는 공간이 이상적입니다.
2.  **현실적인 대안**: 하지만 어떤 문서가 관련 있을지 미리 아는 것은 불가능합니다. <br>
따라서 차선책은 **모든 문서들을 서로 최대한 멀리 떨어뜨려 놓는 것**입니다. <br>
이렇게 하면 사용자의 검색어가 특정 문서와 가까울 때, 그 주변에 있는 다른 (관련 없는) 문서들이 함께 검색될 가능성이 줄어들어 정밀도(precision)가 높아집니다.

# Methodology
## 단계 1: '문서 공간의 밀도'를 측정 가능한 지표로 정의하기


<p align="center">
  <img alt="표1" src="https://i.imgur.com/dts3edJ.png" referrerpolicy="no-referrer" loading="lazy" />
</p>

* '공간이 빽빽하다' 또는 '널찍하다'와 같은 추상적인 개념을 구체적인 숫자로 측정할 수 있는 **'공간 밀도(Space Density)' 지표**를 정의했습니다.

* 어떻게 계산했는가?:
    1.  **가장 이상적이지만 비효율적인 방법**: 공간 내의 모든 문서 쌍($D_i, D_j$) 간의 유사도($s$)를 전부 더하는 것입니다.<br>
    하지만 이 방식은 문서가 $n$개일 때 계산량이 $n^2$에 비례하여 매우 비효율적입니다.

        $$F = \sum_{i=1}^{n}\sum_{j=1, i \ne j}^{n}s(D_{i},D_{j})$$

    2.  **실용적인 대안**: 계산량을 줄이기 위해, 전체 문서 공간의 '무게 중심'에 해당하는 '메인 센트로이드(Main Centroid, $C^*$)'를 계산합니다. <br>
    그리고 각 문서 벡터($D_i$)가 이 메인 센트로이드와 얼마나 유사한지를 모두 더하여 공간 밀도 $Q$를 정의합니다.<br>

    <p align="center">
    <img alt="표1" src="https://i.imgur.com/TxfKSSd.png" referrerpolicy="no-referrer" loading="lazy" />
    </p>


    <br>$$Q = \sum_{i=1}^{n}s(C^{*},D_{i})$$

    3.  **클러스터 기반 측정**: 문서들을 여러 클러스터로 그룹화한 경우, '클러스터 내부의 평균 유사도(x)'와 '클러스터 간의 평균 유사도(y)'를 계산하고, 그 비율인 `y/x`를 밀도 척도로 사용했습니다.

## **단계 2: (성능 → 공간 밀도) 알려진 성능의 인덱싱이 공간 밀도에 미치는 영향 분석**

* **WHAT (무엇을 했는가?)**: 이미 성능이 좋다고 알려진 인덱싱 방법과 나쁘다고 알려진 방법을 각각 적용한 뒤, 그 결과로 생성된 문서 공간의 밀도가 정말 가설대로 변하는지 측정했습니다.

* **HOW (어떻게 분석했는가?)**:
    * **기준(Baseline)**: 단순 용어 빈도(TF) 가중치 방식을 기준으로 삼았습니다.
    * **좋은 방법 (TF-IDF)**: 검색 성능을 약 14% 향상시키는 것으로 알려진 TF-IDF 가중치 방식을 적용했습니다.
    * **나쁜 방법 (TF-DF)**: 일부러 성능을 저하(약 10% 감소)시키도록 설계한 TF-DF(문서 빈도가 높을수록 가중치를 높게 부여) 방식을 적용했습니다.

* **WHY (왜 이 행동을 했는가?)**: '좋은 성능 → 낮은 공간 밀도', '나쁜 성능 → 높은 공간 밀도'라는 인과 관계를 확인하기 위함이었습니다.
    * 만약 이 관계가 성립한다면, '공간 밀도' 신뢰가능능

---

## **단계 3: (공간 밀도 → 성능) 공간 밀도를 인위적으로 조작하여 검색 성능의 변화 측정**

* **WHAT (무엇을 했는가?)**: 이전 단계와 반대로, 문서 공간의 밀도를 인위적으로 낮추거나 높인 뒤 실제 검색 성능(Recall-Precision)이 어떻게 변하는지를 측정했습니다.

* **HOW (어떻게 분석했는가?)**:
    * **공간 분산 (밀도 낮추기)**: 소수의 클러스터에만 등장하거나, 특정 클러스터에만 집중적으로 나타나는 '특이한' 용어들의 가중치를 높였습니다.<br>
    이는 클러스터 간의 경계를 더 명확하게 하여 공간의 밀도를 낮추는 효과를 낳습니다.
    * **공간 압축 (밀도 높이기)**: 여러 클러스터에 걸쳐 고르게 나타나는 '평범한' 용어들의 가중치를 높였습니다.<br>
    이는 클러스터들을 서로 비슷하게 만들어 공간 전체를 뭉치게 만듭니다.

* **WHY (왜 이 행동을 했는가?)**: 2단계에서 확인한 '상관관계'를 넘어 '인과관계'를 입증하기 위함입니다.<br>
만약 인위적으로 공간을 분산시켰을 때 성능이 정말 올라가고, 압축시켰을 때 성능이 내려간다면 **공간의 밀도가 검색 성능의 직접적인 원인**이라는 가설을 매우 강력하게 뒷받침할 수 있기 때문입니다.

---

### **단계 4: '용어 판별 가치(Term Discrimination Value)' 모델 정립**

* **WHAT (무엇을 했는가?)**: 앞선 실험 결과들을 바탕으로, 좋은 용어와 나쁜 용어를 구별하는 '판별 가치(DV)'라는 개념을 수학적으로 모델링했습니다.

* **HOW (어떻게 계산했는가?)**:
    * 어떤 용어 $k$의 판별 가치($DV_k$)는, "전체 문서 공간의 밀도($Q$)"와 "해당 용어 $k$를 모든 문서에서 제거했을 때의 공간 밀도($Q_k$)"의 차이로 정의됩니다.
        $$DV_k = Q_k - Q$$
    * 만약 $DV_k > 0$ 이면, 그 용어를 제거했더니 공간이 더 빽빽해졌다는 의미이므로, 원래 그 용어는 공간을 분산시키는 **'좋은 용어(Good Discriminator)'**입니다.<br>
    반대로 $DV_k < 0$ 이면 공간을 뭉치게 하는 **'나쁜 용어(Poor Discriminator)'**입니다
    

* **WHY (왜 이 행동을 했는가?)**: '좋은 용어는 공간을 분산시킨다'는 아이디어를 구체적인 평가 지표로 만들기 위함입니다. 

# Experiment & Result
