---
layout: post
title: "Latent Dirichlet Allocation (2003)"
date: 2022-12-15
category: Machine Learning
tags: [Topic Modeling, Bayesian Inference, NLP, LDA]
---

# [ë…¼ë¬¸ë¦¬ë·°] Latent Dirichlet Allocation (2003)
> David M. Blei, Andrew Y. Ng, Michael I. Jordan  
> *Journal of Machine Learning Research*, Vol. 3 (2003)  
> [Paper](https://jmlr.org/papers/volume3/blei03a/blei03a.pdf)


## Introduction

í…ìŠ¤íŠ¸ ì½”í¼ìŠ¤(corpus)ë¥¼ í™•ë¥ ì ìœ¼ë¡œ ëª¨ë¸ë§í•˜ë ¤ëŠ” ì‹œë„ëŠ” ì˜¤ë˜ì „ë¶€í„° ì´ì–´ì ¸ ì™”ë‹¤.<br>
ê¸°ì¡´ì˜ ëŒ€í‘œì ì¸ ì ‘ê·¼ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:<br>

### Background
1. **TF-IDF** : ë¬¸ì„œë¥¼ ë‹¨ì–´ì˜ ë¹ˆë„ ë²¡í„°ë¡œ ë³€í™˜

<div id="tfidf_plot" style="width:100%; height:500px; margin: 30px auto; border-radius: 12px; box-shadow: 0 4px 20px rgba(0,0,0,0.08);"></div>

<style>
/* Plotly ì°¨íŠ¸ ìŠ¤íƒ€ì¼ ë³´í˜¸ ë° ê°œì„  */
#tfidf_plot { 
  background: linear-gradient(135deg, #f8fafc 0%, #ffffff 100%);
  padding: 20px;
}
#tfidf_plot, #tfidf_plot > div { width: 100% !important; height: 500px !important; }
#tfidf_plot svg { 
  display: block;
  max-height: none !important; 
  pointer-events: auto !important; 
  overflow: visible !important;
}
/* hover ì‹œ ì°¨íŠ¸ ì•½ê°„ ë¶€ê° */
#tfidf_plot:hover {
  box-shadow: 0 6px 30px rgba(96, 165, 250, 0.15);
  transition: box-shadow 0.3s ease;
}
</style>

<script src="https://cdn.plot.ly/plotly-2.30.0.min.js" charset="utf-8"></script>
<script>
(function() {
  function createChart() {
    const words = ["data", "model", "topic", "bayes", "graph", "markov"];
    const weights = [0.35, 0.25, 0.10, 0.05, 0.15, 0.10];
    // ë‹¨ì–´ë³„ ì„¤ëª… ì¶”ê°€
    const descriptions = {
      "data": "ë°ì´í„°ì…‹ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í‚¤ì›Œë“œ",
      "model": "ëª¨ë¸ë§ ê´€ë ¨ í•µì‹¬ ìš©ì–´",
      "topic": "ì£¼ì œ ëª¨ë¸ë§ì˜ ì¤‘ì‹¬ ê°œë…",
      "bayes": "ë² ì´ì¦ˆ í†µê³„ ê´€ë ¨ ìš©ì–´",
      "graph": "ê·¸ë˜í”„ êµ¬ì¡° í‘œí˜„",
      "markov": "ë§ˆë¥´ì½”í”„ ëª¨ë¸ ì°¸ì¡°"
    };
    const plotDiv = document.getElementById('tfidf_plot');
    if (!plotDiv) {
      console.error('Plot div not found');
      return;
    }
    if (typeof Plotly === 'undefined') {
      console.error('Plotly not loaded, retrying...');
      setTimeout(createChart, 100);
      return;
    }
    // ê·¸ë¼ë°ì´ì…˜ ìƒ‰ìƒ ë°°ì—´
    const colors = weights.map(w => `rgba(96, 165, 250, ${0.5 + w})`);
    const trace = {
      type: 'bar',
      x: words,
      y: weights,
      text: weights.map(w => w.toFixed(2)),
      textposition: 'outside',
      textfont: {
        size: 14,
        color: '#1e3a8a',
        family: 'Roboto, sans-serif',
        weight: 600
      },
      marker: {
        color: colors,
        line: { 
          color: '#3b82f6', 
          width: 2 
        },
        opacity: 0.85
      },
      hovertemplate: 
        '<b style="font-size:16px">%{x}</b><br>' +
        '<span style="color:#3b82f6">â—</span> TF-IDF Weight: <b>%{y:.3f}</b><br>' +
        '<span style="font-size:12px; color:#64748b">%{customdata}</span>' +
        '<extra></extra>',
      customdata: words.map(w => descriptions[w]),
      hoverlabel: {
        bgcolor: 'white',
        bordercolor: '#3b82f6',
        font: { 
          size: 14, 
          family: 'Roboto, sans-serif',
          color: '#1e293b'
        },
        align: 'left'
      }
    };
    const layout = {
      title: { 
        text: 'ğŸ“Š TF-IDF Weight Distribution',
        font: { 
          size: 22,
          color: '#1e3a8a',
          family: 'Roboto, sans-serif',
          weight: 700
        },
        x: 0.5,
        xanchor: 'center'
      },
      xaxis: { 
        title: {
          text: 'Terms',
          font: { size: 16, color: '#475569', weight: 600 }
        },
        tickfont: { size: 14, color: '#64748b' },
        gridcolor: 'rgba(203, 213, 225, 0.3)',
        showline: true,
        linewidth: 2,
        linecolor: '#cbd5e1'
      },
      yaxis: { 
        title: {
          text: 'TF-IDF Weight',
          font: { size: 16, color: '#475569', weight: 600 }
        },
        tickfont: { size: 13, color: '#64748b' },
        range: [0, 0.42],
        gridcolor: 'rgba(203, 213, 225, 0.4)',
        showline: true,
        linewidth: 2,
        linecolor: '#cbd5e1',
        zeroline: true,
        zerolinecolor: '#94a3b8',
        zerolinewidth: 2
      },
      margin: { l: 70, r: 40, t: 80, b: 70 },
      plot_bgcolor: 'rgba(248, 250, 252, 0.5)',
      paper_bgcolor: 'rgba(0,0,0,0)',
      hovermode: 'closest',
      font: { family: 'Roboto, sans-serif' },
      showlegend: false
    };
    const config = {
      responsive: true,
      displayModeBar: true,
      displaylogo: false,
      modeBarButtonsToRemove: ['pan2d', 'lasso2d', 'select2d', 'autoScale2d'],
      toImageButtonOptions: {
        format: 'png',
        filename: 'tfidf_chart',
        height: 600,
        width: 900,
        scale: 2
      }
    };
    // ì°¨íŠ¸ ìƒì„± (ì´ˆê¸°ì—ëŠ” yê°’ì´ 0)
    const initialTrace = {...trace, y: weights.map(() => 0)};
    Plotly.newPlot(plotDiv, [initialTrace], layout, config).then(() => {
      // ì˜¬ë¼ê°€ëŠ” ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼
      Plotly.animate(plotDiv, {
        data: [{y: weights}],
        traces: [0]
      }, {
        transition: {
          duration: 1200,
          easing: 'elastic-out'
        },
        frame: {
          duration: 1200,
          redraw: false
        }
      });
    });
    // hover ì‹œ ë§‰ëŒ€ í™•ëŒ€ íš¨ê³¼
    plotDiv.on('plotly_hover', function(data) {
      const pointIndex = data.points[0].pointIndex;
      const update = {
        'marker.line.width': weights.map((_, i) => i === pointIndex ? 3 : 2),
        'marker.opacity': weights.map((_, i) => i === pointIndex ? 1 : 0.7)
      };
      Plotly.restyle(plotDiv, update, [0]);
    });
    plotDiv.on('plotly_unhover', function() {
      const update = {
        'marker.line.width': 2,
        'marker.opacity': 0.85
      };
      Plotly.restyle(plotDiv, update, [0]);
    });
  }
  if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', createChart);
  } else {
    createChart();
  }
})();
</script>


**ì •ì˜**: ë‹¨ì–´ $t$ê°€ ë¬¸ì„œ $d$ì—ì„œ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ ì¸¡ì •í•˜ëŠ” ê°€ì¤‘ì¹˜. <br> â€œë¬¸ì„œ ë‚´ë¶€ì˜ ìƒëŒ€ì  ë¹ˆë„$(TF)$â€ì™€ â€œì½”í¼ìŠ¤ ì „ì²´ì—ì„œì˜ í¬ì†Œì„±$(IDF)$â€ì˜ ê³±.

* **ìˆ˜ì‹**
  $$
  \mathrm{TF\text{-}IDF}(t, d, D) = \mathrm{TF}(t, d) \times \mathrm{IDF}(t, D)
  $$
  $$
  \mathrm{TF}(t, d) = \frac{f_{t,d}}{\sum_{t'} f_{t',d}}, \qquad
  \mathrm{IDF}(t, D) = \log \left( \frac{N}{1 + n_t} \right)
  $$

  * $f_{t,d}$: ë‹¨ì–´ $t$ì˜ ë¬¸ì„œ $d$ ë‚´ ë“±ì¥ íšŸìˆ˜
  * $N$: ì „ì²´ ë¬¸ì„œ ìˆ˜, $n_t$: ë‹¨ì–´ $t$ë¥¼ í¬í•¨í•œ ë¬¸ì„œ ìˆ˜


* **ì¶œë ¥**: ê° ë¬¸ì„œëŠ” $\mathbb{R}^V$ì˜ ê³ ì • ê¸¸ì´ ë²¡í„°(í¬ì†Œ).

* **ì¥ì **: ê³„ì‚° ê°„ë‹¨, í•´ì„ ì‰¬ì›€, ê²€ìƒ‰/ìœ ì‚¬ë„ì— ê°•í•¨.

* **í•œê³„**: ë‹¨ì–´ ìˆœì„œÂ·ë¬¸ë§¥ ë¬´ì‹œ(BoW), ë™ì˜ì–´/ë‹¤ì˜ì–´ ì²˜ë¦¬ ì•½í•¨, í†µê³„ì  ìƒì„± ì˜ë¯¸ ì—†ìŒ.


2. **Latent Semantic Indexing (LSI)** : íŠ¹ì´ê°’ ë¶„í•´(SVD)ë¡œ ì°¨ì› ì¶•ì†Œ

**ì •ì˜**: TF-IDF í–‰ë ¬ $X\in\mathbb{R}^{V\times M}$ë¥¼ SVDë¡œ ë¶„í•´í•´ **ë‚®ì€ ì°¨ì›ì˜ ì ì¬ ì˜ë¯¸ ê³µê°„**ìœ¼ë¡œ íˆ¬ì˜í•˜ì—¬ ìœ ì‚¬ë„/ê²€ìƒ‰ì„ ê°œì„ .

* **ìˆ˜ì‹ (ë­í¬-(k) ê·¼ì‚¬)**
  $$
  X \approx X_k = U_k \Sigma_k V_k^\top
  $$

  * $U_k \in \mathbb{R}^{V \times k}$: ë‹¨ì–´ ì ì¬ì¶•, $V_k \in \mathbb{R}^{M \times k}$: ë¬¸ì„œ ì ì¬í‘œí˜„, $\Sigma_k$: íŠ¹ì´ê°’ ëŒ€ê°í–‰ë ¬
  * ë¬¸ì„œ $j$ì˜ ì„ë² ë”©: $\mathbf{d}_j = \Sigma_k V_k^\top[:,j]$
  * ì¿¼ë¦¬ $\mathbf{q}$ íˆ¬ì˜: $\tilde{\mathbf{q}} = \Sigma_k^{-1} U_k^\top \mathbf{q}$ í›„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„

* **íš¨ê³¼**: ë…¸ì´ì¦ˆ ì œê±°, **ë™ì˜ì–´/ë‹¤ì˜ì–´** ì¼ë¶€ í•´ê²°(ì„ í˜• ê²°í•©ìœ¼ë¡œ ì£¼ì œì¶• í•™ìŠµ)

* **ì¥ì **: ë¹ ë¥¸ ê·¼ì‚¬ ê²€ìƒ‰, ì„ í˜•ëŒ€ìˆ˜ ê¸°ë°˜ êµ¬í˜„ ìš©ì´

* **í•œê³„**: **ìƒì„± ëª¨ë¸ ì•„ë‹˜**(í™•ë¥  ì˜ë¯¸ ë¶€ì¡±), ìƒˆ ë¬¸ì„œ **fold-in** í•„ìš”, k ì„ íƒ ë¯¼ê°, ìŒìˆ˜ í—ˆìš©(í•´ì„ì„± ì•½í™”)

3. **Probabilistic LSI (pLSI)** : ë‹¨ì–´ë¥¼ *ì ì¬ ì£¼ì œ(topic)* ì˜ í˜¼í•©ìœ¼ë¡œ í‘œí˜„

**ì •ì˜**: ë¬¸ì„œ $d$ì™€ ë‹¨ì–´ $w$ì˜ ê²°í•©ì„ **ì ì¬ í† í”½ $z$** ë¡œ ë§¤ê°œí•˜ëŠ” í™•ë¥  ëª¨ë¸. <br>
 ê° ë¬¸ì„œëŠ” í† í”½ì˜ í˜¼í•©ë¹„ $p(z\mid d)$ë¥¼ ê°–ê³ , ë‹¨ì–´ëŠ” $p(w\mid z)$ë¡œ ìƒì„±ëœë‹¤.

* **ìˆ˜ì‹**
  $$
  p(d, w) = p(d) \sum_{z=1}^{K} p(w \mid z) \, p(z \mid d)
  $$

  * ë¬¸ì„œ $d$ì˜ í† í”½ ë¶„í¬: $\mathbf{\pi}_d = p(z \mid d)$
  * í† í”½ $z$ì˜ ë‹¨ì–´ ë¶„í¬: $\phi_z = p(w \mid z)$

* **ì¶”ì •(EM ê°œìš”)**

  * **E-step**: 
    $$
    p(z \mid d, w) \propto p(w \mid z) \, p(z \mid d)
    $$
  * **M-step**:
    $$
    p(w \mid z) \propto \sum_d n(d, w) \, p(z \mid d, w)
    $$
    $$
    p(z \mid d) \propto \sum_w n(d, w) \, p(z \mid d, w)
    $$

* **ì¥ì **: LSIì— **í™•ë¥ ì  ì˜ë¯¸** ë¶€ì—¬, ë¬¸ì„œì— **ë‹¤ì¤‘ í† í”½ í˜¼í•©** í—ˆìš©

* **í•µì‹¬ í•œê³„**:

  * $\mathbf{\pi}_d$ê°€ **í›ˆë ¨ ë¬¸ì„œ ì§€í‘œì— ë¬¶ì„** â†’ **ìƒˆ ë¬¸ì„œì˜ ì‚¬ì „ í™•ë¥  ì •ì˜ ë¶ˆê°€** (ì§„ì •í•œ ìƒì„± ëª¨ë¸ ì•„ë‹˜)
  * íŒŒë¼ë¯¸í„° ìˆ˜ $O(KV+KM)$ë¡œ **ë¬¸ì„œ ìˆ˜ $M$** ì— ì„ í˜• ì¦ê°€ â†’ **ê³¼ì í•©** ìš©ì´

ì´ëŸ¬í•œ ë°©ë²•ë“¤ì€ ë‹¤ìŒ í•œê³„ë¥¼ ê°€ì§„ë‹¤.

1. **ë¬¸ì„œ ë‹¨ìœ„ì˜ ìƒì„± í™•ë¥  ëª¨ë¸ ë¶€ì¬**  
   â†’ pLSIëŠ” í•™ìŠµëœ ë¬¸ì„œ ì™¸ì˜ ìƒˆë¡œìš´ ë¬¸ì„œì— ëŒ€í•´ í™•ë¥ ì„ ì •ì˜í•  ìˆ˜ ì—†ë‹¤.  
2. **íŒŒë¼ë¯¸í„° ìˆ˜ í­ë°œ ë° ê³¼ì í•© ë¬¸ì œ**  
   â†’ pLSIëŠ” ë¬¸ì„œ ìˆ˜ $M$ì— ë¹„ë¡€í•˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ í•™ìŠµí•´ì•¼ í•œë‹¤.  

> ì´ì— ë³¸ ë…¼ë¬¸ì€ **Latent Dirichlet Allocation (LDA)** ë¥¼ ì œì•ˆí•˜ì˜€ë‹¤.<br>
> LDAëŠ” ê° ë¬¸ì„œë¥¼ **ì—¬ëŸ¬ ì£¼ì œì˜ í™•ë¥ ì  í˜¼í•©**ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” **3ê³„ì¸µ ê³„ì¸µì  ë² ì´ì¦ˆ ëª¨ë¸(Hierarchical Bayesian Model)** ì´ë‹¤.

### Bayesian Model

**ë² ì´ì¦ˆ ëª¨ë¸(Bayesian Model)** ì€ ë°ì´í„°ê°€ ìƒì„±ë˜ëŠ” í™•ë¥ ì  ê³¼ì •ì„ **ì‚¬ì „(prior)**, **ìš°ë„(likelihood)**, **ì‚¬í›„(posterior)** ì˜ ì„¸ ê´€ê³„ë¡œ ì„¤ëª…í•˜ëŠ” í†µê³„ì  í‹€ì´ë‹¤.

1. **ì‚¬ì „ë¶„í¬ (Prior)**  
   - ë°ì´í„°ê°€ ê´€ì¸¡ë˜ê¸° ì „ì— íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ë¯¿ìŒ(ë¶ˆí™•ì‹¤ì„±)ì„ í™•ë¥ ë¶„í¬ë¡œ í‘œí˜„  
   - ì˜ˆ: $\theta \sim \mathrm{Dir}(\alpha)$

2. **ìš°ë„ (Likelihood)**  
   - ì£¼ì–´ì§„ íŒŒë¼ë¯¸í„°ë¡œë¶€í„° ë°ì´í„°ê°€ ìƒì„±ë  í™•ë¥   
   - ì˜ˆ: $w_n \sim p(w_n \mid \theta, \beta)$

3. **ì‚¬í›„ë¶„í¬ (Posterior)**  
   - ë°ì´í„°ë¥¼ ê´€ì°°í•œ í›„ íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ìˆ˜ì •ëœ ë¯¿ìŒ  
   - ë² ì´ì¦ˆ ì •ë¦¬ë¡œ ê³„ì‚°:
     $$
     p(\theta \mid w) = \frac{p(w \mid \theta)\, p(\theta)}{p(w)}
     $$

ì´ êµ¬ì¡°ë¥¼ ì´ìš©í•˜ë©´ **ëª¨ìˆ˜ì˜ ë¶ˆí™•ì‹¤ì„±ê¹Œì§€ ëª¨ë¸ë§**í•  ìˆ˜ ìˆìœ¼ë©° ìƒˆë¡œìš´ ë°ì´í„°ê°€ ë“±ì¥í•´ë„ **ì‚¬í›„â†’ì‚¬ì „ ê°±ì‹ (posterior update)** ì„ í†µí•´ ìì—°ìŠ¤ëŸ½ê²Œ ì ì‘í•œë‹¤.

> ì¦‰, LDAëŠ” â€œë¬¸ì„œê°€ ì£¼ì œì˜ í˜¼í•©ìœ¼ë¡œë¶€í„° ìƒì„±ëœë‹¤â€ëŠ” ê³¼ì •ì„  <br>
> ë² ì´ì¦ˆì  í™•ë¥  ëª¨ë¸ë¡œ í‘œí˜„í•œ ê²ƒì´ë‹¤.


## Method

### 1. LDAì˜ ê°œë…

LDAëŠ” ê° ë¬¸ì„œê°€ $K$ê°œì˜ ì ì¬ ì£¼ì œ(topic)ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤ê³  ê°€ì •í•œë‹¤.<br>
ê° ì£¼ì œëŠ” ë‹¨ì–´ ë¶„í¬ë¡œ í‘œí˜„ë˜ë©°, ë¬¸ì„œëŠ” ì´ ì£¼ì œë“¤ì˜ í˜¼í•©ìœ¼ë¡œ êµ¬ì„±ëœë‹¤.

$$
\text{Document} \sim \sum_{k=1}^{K} \theta_k \cdot \text{Topic}_k, \quad
\text{Topic}_k \sim \text{Multinomial}(\beta_k)
$$



ì—¬ê¸°ì„œ $\theta$ëŠ” ë¬¸ì„œë³„ ì£¼ì œ ë¹„ìœ¨ì´ë©°, $\beta_k$ëŠ” ì£¼ì œë³„ ë‹¨ì–´ ë¶„í¬ì´ë‹¤.


### 2. Generative Process

ê° ë¬¸ì„œ $d$ì— ëŒ€í•´ ë‹¤ìŒ ê³¼ì •ì„ ë”°ë¥¸ë‹¤:

1. ë¬¸ì„œ ê¸¸ì´ $N_d \sim \text{Poisson}(\xi)$  
2. ì£¼ì œ ë¶„í¬ $\theta_d \sim \text{Dir}(\alpha)$  
3. ê° ë‹¨ì–´ $n = 1, \dots, N_d$ì— ëŒ€í•´  
   - ì£¼ì œ ì„ íƒ: $z_{dn} \sim \text{Multinomial}(\theta_d)$  
   - ë‹¨ì–´ ì„ íƒ: $w_{dn} \sim p(w_{dn} | z_{dn}, \beta)$  

ì¦‰, ë‹¨ì–´ëŠ” ë¬¸ì„œ ë‚´ ì£¼ì œ ë¶„í¬ $\theta_d$ì— ë”°ë¼ ì„ íƒëœ ì£¼ì œ $z_{dn}$ë¡œë¶€í„° ìƒì„±ëœë‹¤.

---

### ğŸ§© **3. ìˆ˜ì‹ í‘œí˜„**

í•˜ë‚˜ì˜ ë¬¸ì„œì— ëŒ€í•œ ê²°í•© í™•ë¥ ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
p(\theta, z, w | \alpha, \beta)
= p(\theta | \alpha) \prod_{n=1}^{N} p(z_n | \theta) p(w_n | z_n, \beta)
$$

ì´ë¥¼ ì ë¶„ ë° í•©ì‚°í•˜ì—¬ ë¬¸ì„œì˜ ì£¼ë³€í™•ë¥ ì„ ì–»ëŠ”ë‹¤.

$$
p(w | \alpha, \beta)
= \int p(\theta | \alpha) 
\prod_{n=1}^{N} \sum_{z_n} p(z_n | \theta)p(w_n | z_n, \beta)
\, d\theta
$$

---

### ğŸ§® **4. ê·¸ë˜í”½ ëª¨ë¸**

<p align="center">
<img src="https://miro.medium.com/v2/resize:fit:1200/1*Wn8O6qDMPNsM0YmXUyXyZg.png" width="500"/>
</p>

- **Î±, Î²**: corpus-level íŒŒë¼ë¯¸í„°  
- **Î¸**: ë¬¸ì„œ ìˆ˜ì¤€ ì£¼ì œ ë¶„í¬  
- **z, w**: ë‹¨ì–´ ìˆ˜ì¤€ì˜ ìˆ¨ì€ ì£¼ì œì™€ ê´€ì¸¡ ë‹¨ì–´  

> ë¬¸ì„œê°€ í•˜ë‚˜ì˜ ì£¼ì œì— ê³ ì •ë˜ì§€ ì•Šê³ , ì—¬ëŸ¬ ì£¼ì œì˜ í˜¼í•©ìœ¼ë¡œ í‘œí˜„ëœë‹¤ëŠ” ì ì´ LDAì˜ í•µì‹¬ì´ë‹¤.

---

### ğŸ” **5. Variational Inference**

í›„í–‰ ë¶„í¬ $p(\theta, z | w, \alpha, \beta)$ ëŠ” ì§ì ‘ ê³„ì‚°ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤.  
ë”°ë¼ì„œ **Variational Inference** ë¥¼ í†µí•´ ê·¼ì‚¬í•œë‹¤.

ê·¼ì‚¬ ë¶„í¬ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•œë‹¤:

$$
q(\theta, z | \gamma, \phi)
= q(\theta | \gamma) \prod_{n=1}^{N} q(z_n | \phi_n)
$$

ì´ë•Œ KL divergenceë¥¼ ìµœì†Œí™”í•˜ëŠ” $\gamma, \phi$ë¥¼ ì°¾ëŠ”ë‹¤.

$$
(\gamma^\*, \phi^\*) 
= \arg\min_{\gamma, \phi} D_{KL}
\big(q(\theta, z | \gamma, \phi) \,||\, p(\theta, z | w, \alpha, \beta)\big)
$$

ì—…ë°ì´íŠ¸ ê·œì¹™ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:

$$
\phi_{ni} \propto \beta_{i w_n} \exp\{ \Psi(\gamma_i) - \Psi(\sum_j \gamma_j)\}
$$

$$
\gamma_i = \alpha_i + \sum_{n=1}^{N} \phi_{ni}
$$

---

### ğŸ§  **6. Parameter Estimation (EM Algorithm)**

1. **E-step:** ê° ë¬¸ì„œë³„ $(\gamma_d, \phi_d)$ ì—…ë°ì´íŠ¸  
2. **M-step:**  
   $$
   \beta_{ij} \propto \sum_d \sum_n \phi_{dni} w_{dn}^j
   $$
   $\alpha$ëŠ” Newton-Raphson ë°©ë²•ìœ¼ë¡œ ê°±ì‹ ëœë‹¤.

ì´ ê³¼ì •ì„ ë°˜ë³µí•˜ì—¬ ìˆ˜ë ´ì‹œí‚¨ë‹¤.

---

## **Experiment**

### ğŸ“š **Dataset**

| ë°ì´í„°ì…‹ | ì„¤ëª… |
|-----------|------|
| **TREC AP** | 16,000 ë‰´ìŠ¤ ê¸°ì‚¬, 23,000 ë‹¨ì–´ |
| **C. Elegans** | 5,225 ë…¼ë¬¸ ì´ˆë¡ |
| **EachMovie** | ì˜í™” ì¶”ì²œ í˜‘ì—… í•„í„°ë§ ë°ì´í„° |

---

### ğŸ”¬ **ë¹„êµ ëª¨ë¸**

| ëª¨ë¸ | ì„¤ëª… |
|------|------|
| **Unigram** | ë‹¨ì¼ ë‹¤í•­ë¶„í¬ ëª¨ë¸ |
| **Mixture of Unigrams** | ë¬¸ì„œë³„ ë‹¨ì¼ ì£¼ì œ |
| **pLSI** | ë¬¸ì„œ-ë‹¨ì–´ ìŒ ê¸°ë°˜ í™•ë¥  ëª¨ë¸ |
| **LDA** | ë¬¸ì„œë³„ ì£¼ì œ í˜¼í•© + ìƒì„± ê°€ëŠ¥ ëª¨ë¸ |

---

### ğŸ“ˆ **ê²°ê³¼: Perplexity ë¹„êµ**

<p align="center">
<img src="https://miro.medium.com/v2/resize:fit:1200/1*RpVqvAip9oD9VyMBQYDWvA.png" width="520"/>
</p>

- **LDA**ëŠ” pLSIë³´ë‹¤ **ì¼ê´€ë˜ê²Œ ë‚®ì€ Perplexity**ë¥¼ ê¸°ë¡  
- Mixture of Unigramsì€ $k$ ì¦ê°€ ì‹œ **ê·¹ì‹¬í•œ ê³¼ì í•©**  
- pLSIëŠ” íŒŒë¼ë¯¸í„° ìˆ˜ $O(Mk)$ â†’ **ë°ì´í„°ì…‹ í¬ê¸°ì— ë¹„ë¡€**  
- LDAëŠ” $O(kV)$ë¡œ **corpus í¬ê¸°ì— ë¬´ê´€í•œ ì•ˆì •ì  ì„±ëŠ¥**

---

### ğŸ¨ **Topic ì˜ˆì‹œ**

| Topic | ìƒìœ„ ë‹¨ì–´ (Top Words) |
|-------|------------------------|
| **Arts** | film, music, actor, play, opera |
| **Budgets** | tax, federal, congress, billion |
| **Children** | family, parents, care, child |
| **Education** | school, teacher, students, public |

> ì£¼ì œë³„ ë‹¨ì–´ ë¶„í¬ $\beta_k$ê°€ ì˜ë¯¸ ìˆëŠ” í´ëŸ¬ìŠ¤í„°ë¡œ ìˆ˜ë ´í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

---

## **Conclusion**

LDAëŠ” ê¸°ì¡´ pLSIì˜ êµ¬ì¡°ì  í•œê³„ë¥¼ ê·¹ë³µí•œ  
**ì™„ì „í•œ í™•ë¥  ìƒì„± ëª¨ë¸(generative probabilistic model)** ì´ë‹¤.  

- **ë¬¸ì„œ ìƒì„± ëª¨ë¸ë§ ê°€ëŠ¥** (unseen ë¬¸ì„œì—ë„ í™•ë¥  í• ë‹¹)  
- **ì£¼ì œ í˜¼í•© í‘œí˜„**ìœ¼ë¡œ ë¬¸ì„œì˜ ë‹¤ì¤‘ ì˜ë¯¸ë¥¼ í¬ì°©  
- **ë³€ë¶„ì¶”ë¡  ê¸°ë°˜ EM í•™ìŠµ**ìœ¼ë¡œ ëŒ€ê·œëª¨ corpusì— ì ìš© ê°€ëŠ¥  

LDAëŠ” ì´í›„ ìˆ˜ë§ì€ í™•ì¥ ëª¨ë¸ì˜ í† ëŒ€ê°€ ë˜ì—ˆë‹¤.  
ì˜ˆë¥¼ ë“¤ì–´,  
**CTM (Correlated Topic Model)**, **HDP (Hierarchical Dirichlet Process)**,  
**DTM (Dynamic Topic Model)**, **Neural LDA**, **BERTopic** ë“±ì´ ëª¨ë‘  
LDAì˜ ë² ì´ì¦ˆì  í‹€ ìœ„ì—ì„œ ë°œì „í–ˆë‹¤.

---

## ğŸ§  **Discussion & Conclusion**

| í•­ëª© | ì„¤ëª… |
|------|------|
| ğŸ¯ **í•µì‹¬ ì•„ì´ë””ì–´** | ë¬¸ì„œ = ì£¼ì œì˜ í™•ë¥ ì  í˜¼í•© |
| ğŸ“Š **ìˆ˜í•™ì  êµ¬ì¡°** | Dirichletâ€“Multinomial conjugacy |
| ğŸ’¡ **ì¥ì ** | í•´ì„ë ¥, í™•ì¥ì„±, unseen ë¬¸ì„œ ëŒ€ì‘ |
| âš ï¸ **í•œê³„** | bag-of-words ê°€ì • â†’ ë¬¸ë§¥/ìˆœì„œ ì •ë³´ ì†ì‹¤ |
| ğŸ”® **í›„ì† ì—°êµ¬** | CTM, DTM, HDP, Neural LDA, BERTopic ë“± |

---

> â€œLDAëŠ” â€˜ë‹¨ì–´ì˜ ì§‘í•©â€™ ì†ì—ì„œ *ì˜ë¯¸ì˜ êµ¬ì¡°*ë¥¼ ë°œê²¬í•˜ë ¤ëŠ”  
> ë² ì´ì¦ˆ í™•ë¥ ë¡ ì  ì–¸ì–´ ëª¨ë¸ì˜ ì¶œë°œì ì´ë‹¤.â€ â€” *Blei et al., 2003*

