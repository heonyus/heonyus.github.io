---
layout: post
title: "SHAP(2017)"
date: 2025-11-03
description: "A Unified Approach to Interpreting Model Predictions"
tags:
  - XAI
---
# Introduction
이전에 살펴보았던 [LIME](https://heonyus.github.io/2025/11/LIME(2016).html)은 근처 점들을 샘플링해 작은 선형모델들로 흉내를 냅니다.
근데 이게 수학적으로 최선임을 증명한 규칙이라기보다는 경험상 그럴듯해서 정해 놓은 규칙(heuristic)이여서 이 설정들에서는 공리(axiom)적으로 이게 유일하게 옳다는 보장이 없죠.

저자들은 계속해서 모델이 어떤 예측을 했을때 각 feature가 얼마나 그 예측에 기여를 했는지 **공정**하게 나누고 싶어합니다.

<img src="https://i.imgur.com/HIn64Hm.png" alt="Shapley explanation" width="400" referrerpolicy="no-referrer">

본 논문은 이 공정하게 나누는 기법을 **게임이론**의 **shapley value**에서 착안해 제안합니다.

이때 사용하는 SHAP 공리(axioms)(모델의 예측을 공정하게 feature별로 분배하려면 반드시 만족해야 하는 수학적 조건)라는 것이 있습니다.

1. Efficiency (효율성)
모든 feature의 기여도( $\phi_i$ ) 합이 전체 예측값과 평균 예측값의 차이와 같아야 한다.
즉, 기여도의 총합 = 모델 출력의
2. Symmetry (대칭성)


# Method
SHAP(SHapley Additive exPlanations)는 shapley value를 사용해 특정 입력 $x$에 대한 그 순간의 예측 $f(x)$을 각 $\text{feature}(x_i)$가 기여한 정도 $\phi_i$로 가산분배하는 additive feature attribution 방법입니다.

우리가 지금 집중하는 것은 "바로 이 샘플 $x$에서 모델이 왜 이렇게 예측했는가?" 입니다.
특정 입력 $x$에 대한 그 순간의 예측 $f(x)$을 기여도로 분배하는 이유죠.

각 분해된 값들이 합쳐져서 **정확히 원래의 예측값 $f(x)$**이 되어야(local fidelity) 산출값을 사후 검증 (post-hoc verification)할 수 있습니다.

   - 공정성(일관성)을 보장하기 위해서는 모든 feature의 한계 기여(marginal contribution)을 균형있게 평균하는 가산 모델이 필요합니다(shapley 공리).
   - 특징을 하나씩 “합류”시킬 때 생기는 추가 이익(=한계 기여)을 **가능한 모든 합류 순서(또는 부분집합)**에 대해 치우침 없이 평균해서 각 특징의 몫을 정하면 **일관성(모델이 그 특징에 더 의존할수록 기여도도 줄지 않음)**이 보장된다는 뜻

## 해석 가능한 표현
feature $x_i$의 설명을 얻기 위해서는 해당 feature $x_i$가 예측값에 얼마나 기여를 했는지 알아야합니다.
그러기 위해 본 논문에서는 기여도 $\phi_i$를 계산할때 사용하는 입력을 **해석 가능한 표현(interpretable representation)** $x'$로 바꿉니다.

$\phi_i$를 계산하기 위해서는 해당 feature $x_i$가 켜져있는(on)상태와 꺼져있는(off)상태에서의 모델 예측값 차이를 알아야합니다.

- $\phi_i$: 해당 입력 $x$에서 feature $x_i$의 기여(설명)값
- 본질적으로 Shapley value
- 이 기여도들이 더해져서 예측을 복원

이 부분은 뒤에서 후술하겠습니다.

어쨌든 지금은 원래 입력 $x$를 해석 가능한 표현 $x'$로 바꾸는 방법에 집중합시다.

복잡한 원 입력 \\(x\\)를 해석 가능한 표현(interpretable representation) \\(x' \in \\{0,1\\}^M\\)로 바꿉니다.
즉, 각 특징을 **on(1)/off(0)**로 설명하는 **이진 벡터**입니다.

\\[
h_x:\\{0,1\\}^M \to \mathcal{X}, \qquad h_x(x') = M_S(x), \; S=\\{i \mid x'_i=1\\}
\\]
(해석공간 → 원공간 매핑; 활성 특성 \\(S\\)는 원값 유지, 비활성은 **참조값/조건부 기대**로 대체)

- **텍스트**: 문장 \\(x\\)를 토큰으로 쪼개고 각 토큰의 on/off로 \\(x'\\) 구성  
  - off 토큰은 [MASK]/패딩 또는 **MLM 조건부 대체**로 채워 \\(h_x(x')\\)를 만듬
- **이미지**: 이미지를 **슈퍼픽셀**로 나누고 각 영역의 on/off로 \\(x'\\) 구성  
   - off 영역은 **인페인팅/블러/평균 색** 등으로 대체하여 \\(h_x(x')\\)를 만듬

이때 사용하는 비활성 feature의 참조값 대체 부분도 후술!

이렇게 feature들을 분리해서 feature를 $x'$으로 키고 끌 수 있게 만들었습니다.
특징을 선택적으로 켰다/껐다 보며 그 특징이 들어오면 예측값이 얼마나 달아오르는가를 측정합니다.

그럼 이 $x'$를 어떻게 활용하면 될지 살펴봅시다.

## Additive Feature Attribution

아까 이야기 했던 Shapley value $\phi_i$는 특정입력 $x$에서 특징 $x_i$가 예측에 얼마나 기여했는지 나타내는 설명값이라고 이야기 했더랬죠.
그럼 우리는 이 설명값 $\phi_i$들과 입력값을 설명가능한 형태로 만든 $x'$를 지지고 볶아 원래의 블랙박스 모델 $f$의 예측을 각 feature의 기여로 표현해주는 가산형 설명모델 $g$를 정의합니다.

즉, 복잡한 원래 모델 $f$가 특정 입력 $x$에서 출력한 예측값 $f(x)$를 해석 가능한 형태로 변환한 입력 $x'$의 각 요소가 얼마나 기여했는지를 통해 정확히 복원하려는 것입니다.

$$
g(z') = \phi_0 + \sum_{i=1}^{M}\phi_i z'_i
$$

- **$z'$ :** $x'$와 같은 스위치 벡터, 특정 부분집합 $S\subseteq\\{1,\dots,M\\}$를 활성화할때 사용되는 샘플
- **$g(z')$ :** 스위치 벡터를 입력받아 예측값을 가산 합 형태로 복원하는 **설명모델**
- **$\phi_0$ :** 아무 특징도 사용하지 않았을때의 기본 예측값(base value), 보통 $\mathbb{E}[f(X)]$
- **$M$ :** 전체 해석가능한 feature의 개수

각 feature의 효과가 더해져 예측값을 구성해야만 나중에 각 $\phi_i$의 크기를 보고 "이 특징이 예측에 얼마나 기여했는가"를 직관적으로 해석할 수가 있겠죠.

여기서 $z'_i$가 1이면 해당 feature의 기여 $\phi_i$가 더해지고, 0이면 더해지지 않습니다.

전체 식은 "활성화된 feature들의 기여도 합 + 베이스값"으로 원래 모델의 예측값으로 정확히 복원된답니다.

### Shapley 값 정의(정확식)

총 특성 수 $M$, 집합 $N=\{1,\dots,M\}$, 부분집합 $S \subseteq N\setminus\{i\}$에 대해:
$$
\phi_i(f, x) = \sum_{S \subseteq N\setminus\{i\}} \frac{|S|!\,(M-|S|-1)!}{M!} \Big[f_{S\cup\{i\}}(x) - f_S(x)\Big].
$$

이때 *세 가지 공리*를 만족합니다.

- *Local accuracy(국소 정확성)*: $f(x) = \phi_0 + \sum_i \phi_i$  
- *Missingness(결측 무기여)*: 관찰에 부재한 특성은 $\phi_i=0$  
- *Consistency(일관성)*: 어느 모델에서든 특성 i의 *주변 기여*가 증가하면 $\phi_i$는 *감소하지 않음*

## KernelSHAP(모델 불가지론적 근사)

정확식을 직접 계산하기 어렵기에, LIME과 유사한 *가중 최소제곱 회귀*로 $\phi$를 추정합니다.
$$
\min_{\phi}\; \sum_{z'} \pi_x(z')\,\big(f_x(z') - g(z')\big)^2
\quad\text{s.t.}\quad g(z')=\phi_0 + \sum_i \phi_i z'_i
$$
여기서 *SHAP 커널*은
$$
\pi_x(z') \,=\, \frac{M-1}{\binom{M}{|z'|}\,|z'|\,(M-|z'|)},
$$
$|z'|$는 켜진 특성의 개수입니다. 이 커널 선택이 Shapley 공리를 만족하도록 만듭니다. 실무에서는 *배경 샘플(Background set)* 을 수십~수백 개 선택해 조건부 기대값을 근사합니다.

## DeepSHAP(딥러닝 근사)

*DeepLIFT*의 역전파 규칙을 Shapley 값에 맞게 선택해 *층별 기여 규칙*을 적용, 다층 신경망의 $\phi$를 효율적으로 근사합니다. 배경 배치에 대해 평균하여 안정화합니다.

## TreeSHAP(트리 계열의 정확/준정확 해법)

의사결정나무/부스팅/랜덤포레스트에 대해 Shapley 값을 *다항시간*에 계산하는 동적계획 알고리즘입니다. 경로 상의 분기 확률을 누적해 각 특성이 예측에 미친 *마진 기여*를 정확하게 산출합니다. 또한 *상호작용 값*(SHAP interaction values)도 정의해 두 특성의 2차 상호작용을 분리해 보여줄 수 있습니다.

## Linear/Logit SHAP(폐형식)

선형·로지스틱 회귀 등은 가중치와 공분산 구조를 이용해 *폐형식*으로 계산 가능(특히 독립/가우시안 가정하 간단).

# Experiment

원 논문은 *일관성(consistency)* 사용자 실험, *근사 오차*와 *시간 복잡도* 비교, *의료·건강 데이터* 적용 등을 통해 SHAP의 장점을 제시합니다.

- *일관성 사용자 연구*: 특정 특성의 진짜 영향이 커지면 설명값도 커져야 한다는 상식에 대해, SHAP이 *가장 높은 일치율*을 보임.  
- *성능/시간*: KernelSHAP은 모델 불가지론적이되 샘플 수에 비례해 비용이 커짐 → **TreeSHAP**이 트리 계열에서는 *정확하면서도 빠름*.  
- *시각화 툴킷*: *Summary plot*(글로벌 분포), *Dependence plot*(비선형/상호작용), *Force/Waterfall plot*(개별 예측 경로)로 *로컬→글로벌*을 연결.

# Notes

## LIME과의 관계

- 두 방법 모두 *국소 근사*를 사용합니다.  
- 차이점은 *가중 커널/제약식*: SHAP은 Shapley 공리를 만족하도록 설계된 *특수 커널*과 *가산 제약*으로 *유일解*를 유도합니다.  
- 실무적 해석: *일관성 보장*이 중요한 규제/의료/금융에서는 SHAP 선호, *간단 탐색·프로토타이핑* 단계에서는 LIME도 유효.

## IG/DeepLIFT와의 관계

- *IG(Integrated Gradients)* 는 경로 적분으로 기여를 계산(연속치, 미분가능 가정).  
- *DeepLIFT*는 기준 대비 변화량을 *규칙 기반 역전파*로 분해.  
- **DeepSHAP**은 DeepLIFT 규칙을 Shapley에 맞추어 배경 평균을 취한 *근사 SHAP*.

## 상호작용 해석

표준 $\phi_i$는 주로 1차 효과. **SHAP interaction** $\Phi_{i,j}$로 2차 항을 분리:
$$
\Phi_{i,j} = \sum_{S \subseteq N\setminus\{i,j\}} \frac{|S|!\,(M-|S|-2)!}{2(M-1)!}\,\Big[ f_{S\cup\{i,j\}} - f_{S\cup\{i\}} - f_{S\cup\{j\}} + f_S \Big].
$$
대각 원소 $\Phi_{i,i}$는 순수 1차 효과가 됩니다.


# Practical Guide

## 어떤 Explainer를 쓸까?

| 모델 유형 | 추천 Explainer | 장점 | 주의점 |
|---|---|---|---|
| 트리 계열(XGBoost/GBDT/RF) | *TreeSHAP* | 빠르고 정확(정확/준정확) | 큰 앙상블에선 메모리 고려 |
| 신경망(이미지/텍스트) | *DeepSHAP* | 층별 규칙으로 효율적 | 배경 선택 민감 |
| 범용(아무 모델) | **KernelSHAP** | 모델 불가지론 | 샘플링/가중회귀 비용 큼 |
| 선형/로지스틱 | *Linear SHAP* | 폐형식/빠름 | 독립/가우시안 가정 확인 |

## 배경(Background) 선택

- *대표성*: 훈련 분포의 소위 *typical set*에서 수십~수백 개 샘플을 택해 조건부 기대를 근사.  
- *문제 지향*: 반사실 질문이면 *정책상 가능한 상태*만 배경으로(예: 신용 정책 제약).  
- *스케일링*: K-means/medoid로 *요약 배경*을 뽑아 비용 절감.

## 시각화 체크리스트

- *Summary plot*로 전반 중요도와 부호 확인 → *Dependence plot*로 비선형/상호작용 진단 → *Force/Waterfall*로 개별 사례 점검.  
- 분포 꼬리/희귀값이 설명을 좌우하지 않는지 *샘플 가중·winsorizing* 고려.

## 평가 & 검증

- *간섭 테스트*: 상위-$k$ 특성만 남기거나 제거해 성능 변화를 측정(*faithfulness*).  
- *안정성*: 배경/샘플링/시드 변화에 대한 *분산* 보고.  
- *공정성*: 민감 특성/대리 변수의 기여 추정과 *인과-반사실* 점검 병행.


# Limitations & Pitfalls

- *독립성 가정*: KernelSHAP의 간단 구현은 조건부 기대를 *독립 가정*으로 근사하기 쉬움 → 상관 특성에서 과/저평가 위험.  
- *배경 의존성*: Deep/Kernel 계열은 배경 분포에 민감 → 사전 탐색/민감도 분석 필수.  
- *전역 해석 남용*: 로컬 기여의 단순 평균만으로 *인과/정책* 결론을 내리지 말 것(상호작용/분포 이동 반영 필요).


# Conclusion

SHAP은 (i) *공리 기반의 유일解*와 (ii) *실용 알고리즘군(Tree/Deep/Kernel)* 을 함께 제공하는 *현시점 표준*의 로컬 설명 방법입니다.
특히 *트리 계열*에선 정확·고속, *딥러닝*에선 배경 기반 근사로 실용성이 확보됩니다. 다만 *배경/상관/평가 프로토콜*을 엄밀히 관리하지 않으면 설명이 쉽게 왜곡됩니다. 실무에서는 아래 체크리스트를 권장합니다.

- *모델별 Explainer 매칭*(Tree→TreeSHAP, NN→DeepSHAP, 기타→KernelSHAP)  
- *대표적 배경 구성*과 *민감도 분석*(배경/시드/샘플 수)  
- *로컬→글로벌*(summary/dependence/interaction) 계층적 점검  
- *faithfulness/안정성/공정성* 평가를 보고서에 포함
