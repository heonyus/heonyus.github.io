---
layout: post
title: "SHAP(2017)"
date: 2025-11-03
description: "A Unified Approach to Interpreting Model Predictions"
tags:
  - XAI
---
# Introduction
이전에 살펴보았던 [LIME](https://heonyus.github.io/2025/11/LIME(2016).html)은 근처 점들을 샘플링해 작은 선형모델들로 흉내를 냅니다.
근데 이게 수학적으로 최선임을 증명한 규칙이라기보다는 경험상 그럴듯해서 정해 놓은 규칙(heuristic)이여서 이 설정들에서는 공리(axiom)적으로 이게 유일하게 옳다는 보장이 없죠.

저자들은 계속해서 모델이 어떤 예측을 했을때 각 feature가 얼마나 그 예측에 기여를 했는지 **공정**하게 나누고 싶어합니다.

<img src="https://i.imgur.com/HIn64Hm.png" alt="Shapley explanation" width="400" referrerpolicy="no-referrer">

본 논문은 이 공정하게 나누는 기법을 **게임이론**의 **shapley value**에서 착안해 제안합니다.

# Method
SHAP(SHapley Additive exPlanations)는 shapley value를 사용해 특정 입력 $x$에 대한 그 순간의 예측 $f(x)$을 각 $\text{feature}(x_i)$가 기여한 정도 $\phi_i$로 가산분배하는 additive feature attribution 방법입니다.

우리가 지금 집중하는 것은 "바로 이 샘플 $x$에서 모델이 왜 이렇게 예측했는가?" 입니다.
특정 입력 $x$에 대한 그 순간의 예측 $f(x)$을 기여도로 분배하는 이유죠.

각 분해된 값들이 합쳐져서 **정확히 원래의 예측값 $f(x)$**이 되어야(local fidelity) 산출값을 사후 검증 (post-hoc verification)할 수 있습니다.

   - 공정성(일관성)을 보장하기 위해서는 모든 feature의 한계 기여(marginal contribution)을 균형있게 평균하는 가산 모델이 필요합니다(shapley 공리).
   - 특징을 하나씩 “합류”시킬 때 생기는 추가 이익(=한계 기여)을 **가능한 모든 합류 순서(또는 부분집합)**에 대해 치우침 없이 평균해서 각 특징의 몫을 정하면 **일관성(모델이 그 특징에 더 의존할수록 기여도도 줄지 않음)**이 보장된다는 뜻

## 해석 가능한 표현
feature $x_i$의 설명을 얻기 위해서는 해당 feature $x_i$가 예측값에 얼마나 기여를 했는지 알아야합니다.
그러기 위해 본 논문에서는 기여도 $\phi_i$를 계산할때 사용하는 입력을 **해석 가능한 표현(interpretable representation)** $x'$로 바꿉니다.

$\phi_i$를 계산하기 위해서는 해당 feature $x_i$가 켜져있는(on)상태와 꺼져있는(off)상태에서의 모델 예측값 차이를 알아야합니다.
이 부분은 뒤에서 후술하겠습니다.

어쨎든 지금은 원래 입력 $x$를 해석 가능한 표현 $x'$로 바꾸는 방법에 집중합시다.

복잡한 원 입력 \\(x\\)를 해석 가능한 표현(interpretable representation) \\(x' \in \\{0,1\\}^M\\)로 바꿉니다.
즉, 각 특징을 **on(1)/off(0)**로 설명하는 **이진 벡터**입니다.

\\[
h_x:\\{0,1\\}^M \to \mathcal{X}, \qquad h_x(x') = M_S(x), \; S=\\{i \mid x'_i=1\\}
\\]
(해석공간 → 원공간 매핑; 활성 특성 \\(S\\)는 원값 유지, 비활성은 **참조값/조건부 기대**로 대체)

- **텍스트**: 문장 \\(x\\)를 토큰으로 쪼개고 각 토큰의 on/off로 \\(x'\\) 구성  
  - off 토큰은 [MASK]/패딩 또는 **MLM 조건부 대체**로 채워 \\(h_x(x')\\)를 만듬
- **이미지**: 이미지를 **슈퍼픽셀**로 나누고 각 영역의 on/off로 \\(x'\\) 구성  
   - off 영역은 **인페인팅/블러/평균 색** 등으로 대체하여 \\(h_x(x')\\)를 만듬

이때 사용하는 비활성 feature의 참조값 대체 부분도 후술!

이렇게 feature들을 분리해서 feature가 예측값을 설명한 기여도를 $x'$으로 키고 끌 수 있게 만들었습니다.
그럼 이제 해당 on/off 상태를 어떻게 사용해서 기여도 $\phi_i$를 계산하는지 알아봅시다.

## Additive Feature Attribution

