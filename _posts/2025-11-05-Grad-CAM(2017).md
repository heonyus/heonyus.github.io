---
layout: post
title: "Grad-CAM(2017)"
date: 2025-11-05
description: "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization"
tags:
  - XAI
  - Vision
---

# Introduction

본 논문은 어떤 CNN이든 architecture를 안건들이고 target class score를 위해 어디를 봤는지를 heatmap으로 extract하는 method를 제안합니다.

<img src="https://i.imgur.com/yfeLdvX.png" alt="Figure 1" width="600" referrerpolicy="no-referrer">

# Background

Image classification CNN을 생각해보면

- input: image
- mid-level: conv layers
- output: feature map -> fully-connected layers -> softmax layer -> class scores

**Grad-CAM**은 그중 마지막 conv layer feature map을 기준으로 해당 class score를 높이는 데 각 channel이 얼마나 중요한지를 gradient를 통해 계산합니다.
그걸 weighted sum해 class별 **heatmap**을 만드는 method입니다.

# Method

## Problem Setup

그럼 왜 이런 method가 필요했을까요?

기존 visualization method를 생각해봅시다.

- pixel-space gradient methods
    - guided backprop, deconvolution 등
    - 장점: high-resolution(edge, texture 잘 보임)
    - 단점: class-discriminative하지 않음
      - "cat"이든 "dog"이든 거의 비슷한 gradient map이 나옴

<img src="https://i.imgur.com/qkLfuSS.png" alt="Pixel-space Gradient Methods" width="600" referrerpolicy="no-referrer">

- CAM(Class Activation Mapping) methods
    - 마지막에 GAP(Global Average Pooling) -> linear layer -> softmax 구조인 CNN에서만 사용 가능
    - 장점: class별로 어디를 봤는지 잘 나옴(class-discriminative)
    - 단점: 이 structure을 사용하려면 architecture를 바꿔야하고 retrain이 필요함
      - VGG, ResNet, captioning, VQA 같은 모델에는 바로 못 씀

<img src="https://i.imgur.com/0YPHqfQ.png" alt="CAM (Class Activation Mapping)" width="600" referrerpolicy="no-referrer">

그래서 우리는 기존 어떤 CNN구조에 손을 대지 않는 agnostic 하게 만들어버리고 싶다라는 뜻입니다.

## Core Idea

<img src="https://i.imgur.com/i0hizhx.png" alt="Figure 2" width="800" referrerpolicy="no-referrer">

그럼 어느 layer를 기준으로 봐야할까요?
너무 앞단(conv1, conv2) layer은 local edge, texture만 보고 있어서 의미가 부족하고 너무 뒷단(fully-connected layer)는 spatial imformation(공간 정보)가 사라져 있죠.
그래서 저자들은 **마지막 conv layer** $A^k \in \mathbb{R}^{u \times v}$ 를 선택합니다.
- semantic information은 충분히 높음
- spatial resolution도 어느 정도 유지(ex. 14x14 feature map)

그럼 이제 이 feature map을 기준으로 해당 class score를 높이는 데 각 channel이 얼마나 중요한지를 gradient를 통해 계산합니다.

## 1단계: channel-wise importance weight 계산

target class `c`에 대한 score를 $y_c$라고 할때(softmax 이전 logit, "dog class logit" 같은거라고 생각하면 됨)

- $y_c$를 기준으로 **feature map** $A^k$의 각 위치 $(i, j)$에 대한 gradient를 계산

$$
\frac{\partial y_c}{\partial A^k_{ij}}
$$

- 이 gradient를 feature map 전체에 대해 global average pooling

$$
\alpha_k^c = \frac{1}{Z} \sum_{i=1} \sum_{j=1} \frac{\partial y_c}{\partial A^k_{ij}}
$$

- $Z = u \times v$는 feature map 전체 pixel 수

$\alpha_k^c$는 class `c`의 score를 높이는 데 $k$번째 channel 전체가 얼마나 중요한지 **importance weight**를 나타냅니다.
gradient를 평균내서 이 channel이 이 class에 얼마나 민감한지 보는 것이죠.

이게 사실상 해당 conv layer 이후 네트워크의 local linearization 역할을 하는겁니다.

## 2단계: heatmap 생성

각 channel의 forward activation $A^k$에 방금 구한 importance weight $\alpha_k^c$를 weighted sum해 heatmap $M^c$을 만듭니다.

$$
\mathbb{L}^c_{Grad-CAM} = ReLU(\sum_k \alpha_k^c A^k)
$$

- $\mathbb{L}^c \in \mathbb{R}^{u \times v}$: class `c`에 대한 coarse heatmap(ex. 14x14)
  - coarse heatmap이란 Grad-CAM을 통해 얻은 spatial resolution이 높지 않은 heatmap(뭉뚱그려진, 거친)을 의미
    - 보통 CNN의 마지막 conv layer feature map은 14x14, 7x7, 5x5 정도의 spatial resolution을 가짐(원본 이미지보다 훨씬 작아짐)
    - Grad-CAM에서 이 feature map 위에서 각 spatial location importance를 계산해서 heatmap을 만드는데 이것이 **coarse heatmap**임
  
- 마지막에 ReLU쓰는 이유
  - 우리는 해당 class score를 **증가시키는 방향의 신호**에만 관심이 있음
  - 음수값(class를 깎아 내리는 부분)은 잘라 버려 이 class의 evidence가 있는 영역만 보겠다는 이야기

이렇게 얻은 $\mathbb{L}^c_{Grad-CAM}$를 bilinear upsampling 해서 original image size로 키우면 image위에서 올려서 볼 수 있는 Grad-CAM heatmap이 됩니다.

## CAM과의 관계

Grad-CAM은 일반화된 CAM method입니다.

CAM architecture에서는

$$
\hat{y} = \sum_k w_k^c \cdot (\frac{1}{Z} \sum_{i,j} A^k_{ij})
$$
 
본 논문에서는 식 정리를 통해

$$
w_k^c ∝ \sum_{i,j} \frac{\partial Y^c}{\partial A^k_{ij}}
$$

를 보여줍니다.

- 즉, CAM에서 사용하는 class-specific weight $w_k^c$와 **Grad-CAM**에서 사용하는 channel-wise importance weight $\alpha_k^c$는 사실상 같은 역할
- 그래서 CAM은 Grad-CAM의 특별한 경우

## Guided Grad-CAM

여기서 문제가 되는 것은 Grad-CAM heatmap은 14x14 같은 coarse resolution이라 detail이 부족해버립니다.

- pixel-space gradient methods(ex. Guided Backprop)은 high-resolution이지만 class-specific하지 않음
- Grad-CAM은 class-specific하지만 coarse

그래서 둘을 element-wise multiplication으로 합쳐버립니다.

1. Guided Backprop으로 얻은 gradient 기반 high-resolution heatmap $G(x)$
2. Grad-CAM heatmap $\mathbb{L}^c_{Grad-CAM}$을 input image resolution으로 upsampling
3. $Guided Grad-CAM = G(x) \odot upsample(\mathbb{L}^c_{Grad-CAM})$

-> 결과적으로 작은 detail 까지 잘 보이는 high-resolution heatmap을 얻을 수 있고 지금 선택한 class에 해당하는 부분만 살아있는 calss-discriminative heatmap을 얻을 수 있습니다.

## Counterfactual Grad-CAM

조금 변형하면 반대로 이 Class를 더 믿지 않게 만들려면 어디를 가려야할지도 볼 수 있습니다.

원래는 target class score를 높이는 방향으로 gradient를 계산했지만 이제는 반대로 낮추는 방향으로 gradient를 계산합니다.

$$
\alpha_k^c = \frac{1}{Z} \sum_{i,j} -\frac{\partial y_c}{\partial A^k_{ij}}
$$

<img src="https://i.imgur.com/13qKq5p.png" alt="Counterfactual Grad-CAM" width="600" referrerpolicy="no-referrer">

-> 이렇게 만든 heatmap은 여기를 없애면 이 class score가 증가할 것이다 같은 counterfactual explanation에 해당합니다.

# Conclusion

본 논문은 어떤 CNN이든 architecture를 안건들이고 target class score를 위해 어디를 봤는지를 heatmap으로 extract하는 method를 제안합니다.

- Grad-CAM: coarse heatmap 제공
- Guided Grad-CAM: high-resolution heatmap 제공
- Counterfactual Grad-CAM: counterfactual explanation 제공

이 method는 기존 pixel-space gradient methods와 CAM 방법들을 대체할 수 있으며 다양한 응용 분야에서 활용될 수 있습니다.



