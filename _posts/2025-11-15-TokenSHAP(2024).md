---
layout: post
title: "TokenSHAP(2024)"
date: 2025-11-15
description: "TokenSHAP: Interpreting Large Language Models with MonteCarlo Shapley Value Estimation"
tags:
  - XAI
---

# Introduction

요즘 LLM을 실제 서비스에 쓰다보면 이 답변에서 어떤 token이나 prompt 부분이 진짜로 중요한가? 라는 질문이 자연스럽게 나오죠.
그런데 대부분의 XAI methods은 image, tabular data에 맞춰져 있거나 model inner gradient나 attention에 의존적입니다.

LLM API만 쓰는 실제 서비스 입장에서는 이런 methods를 그대로 적용하기가 어렵습니다.

> 본 논문에서는 이러한 현실적인 constraint를 prompt의 각 token(or substring)을 cooperative game theory의 player라고 보고 LLM response가 얼마나 달라지는지를 기준으로 **shapley value**를 추정하는 **TokenSHAP**이라는 방법을 제안합니다.

하지만 shapley value는 원래 모든 subset($2^n$)을 봐야하기 때문에 계산 비용이 올라갑니다.
저자들은 이를 해결하기 위해서 monte carlo smapling으로 subset을 smapling하면서 shapley value를 근사하고 LLM response는 TF-IDF 기반 cosine similarity로 수치화해서 value function으로 쓰는 두가지 methods를 결합합니다.

# Methods

먼저 큰 그림 부터 잡아봅시다.

## Problem Setting

input prompt를 

$$
x = (x_1, x_2, \cdots, x_n) 
$$

라고 할 때 각 token $x_i$가 최종 LLM response에 얼마나 기여하는지를 보고자 합니다.

이걸 게임 이론의 언어로 바꾸면

- player set: $N= \{1, 2, \cdots, n\}$ (각 index가 하나의 token에 대응)
- subset $S \subseteq N$: 일부 token만 남겨놓은 부분적인 prompt
- 가치함수(value function) $v(S)$: 부분 prompt만 넣었을 때의 response quality/similarity

여기서 shapley value $\phi_i$는 "player $i$(token $i$)가 모든 가능한 subset $S$에서 추가될 때 평균적으로 얼마나 기여하냐"를 의미합니다.

$$
\phi_i = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|! (n - |S| - 1)!}{n!} \left( v(S \cup \{i\}) - v(S) \right)
$$